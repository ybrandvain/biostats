[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Applied Biostatistics",
    "section": "",
    "text": "Preface\nThis is the Preface and Frontmatter\nLink to Part 1 - Intro to R\nLink to Part 2 - Summarizing data",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#learning-in-this-era",
    "href": "index.html#learning-in-this-era",
    "title": "Applied Biostatistics",
    "section": "Learning in this era",
    "text": "Learning in this era\nI know you’re dealing with a lot. Every year students are dealing with a lot – from jobs, to supporting family, and all the other challenges of modern college life. Yet, we are all trying to make the most of life in this era. We want to teach, learn, and grow.\nMoreover, I believe this content is increasingly important – statistics is obsessed with the critical evaluation of claims in the face of data, and is therefore particularly useful in uncertain times. Given this focus, and given that you all have different energies, motivations and backgrounds, I am restructuring this course slightly from previous years. The biggest change is a continued de-emphasis on math and programming – that doesn’t mean I’m eliminating these features, but rather that I am streamlining the required math and programming to what I believe are the essentials. For those who want more mathematical and/or computational details (either because you want to push yourself or you need this to make sense of things), I am including a bunch of optional content and support. I am also wrestling with the impact of LLMs in our education (more below).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#i-love-teaching-this-course",
    "href": "index.html#i-love-teaching-this-course",
    "title": "Applied Biostatistics",
    "section": "I love teaching this course",
    "text": "I love teaching this course\nThe content is very important to me. I also care deeply about you. I want to make sure you get all you can / all you need from this course, while recognizing the many challenges we are all facing. One tangible thing I leave you with is this book, which I hope you find useful as you go on in your life. Another thing I leave you with is my concern for your well-being and understanding – please contact me with any suggestions about the pace, content, or structure of this course and/or any life updates which may change how and when you can complete the work.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#course-philosophy-goals",
    "href": "index.html#course-philosophy-goals",
    "title": "Applied Biostatistics",
    "section": "Course philosophy / goals",
    "text": "Course philosophy / goals\nMy motivating goal for this course is to empower you to produce, present, and critically evaluate statistical evidence — especially as applied to biological topics. You should know that statistical models are only models and that models are imperfect abstractions of reality. You should be able to think about how a biological question could be formulated as a statistical question, present graphs which show how data speak to this question, be aware of any shortcomings of that model, and how statistical analysis of a data set can be brought back into our biological discussion.\n\n“By the end of this course…\n\nStudents should be statistical thinkers. \nStudents will recognize that data are comprised of observations that partially reflect chance sampling, & that a major goal of statistics is to incorporate this idea of chance into our interpretation of observations. Thinking this way can be challenging because it is a fundamentally new way to think about the world. Once this is mastered, much of the material follows naturally. Until then, it’s more confusing.\n\n\n Students should think about probability quantitatively.\nThat chance influences observations is CRITICAL to statistics (see above). Quantitatively translating these probabilities into distributions and associated statistical tests allows for mastery of the topic.\n\n\n Students should recognize how bias can influence our results. \nNot only are results influenced by chance, but factors outside of our focus can also drive results. Identifying subtle biases and non-independence is key to conducting and interpreting statistics.\n\n\n Students should become familiar with standard statistical tools / approaches and when to use them. \nRecognize how bias can influence our results. What is the difference between Bayesian and frequentist thinking? How can data be visualized effectively? What is the difference between statistical and real-world significance? How do we responsibly present/ interpret statistical results? We will grapple with & answer these questions over the term.\n\n\n Students should have familiarity with foundational statistical values and concepts. \nStudents will gain an intuitive feel for the meaning of stats words like variance, standard error, p-value, t-statistic, and F-statistic, and will be able to read and interpret graphs, and how to translate linear models into sentences.\n\n\n Students should be able to conduct the entire process of data analysis in R. \nStudents will be able to utilize the statistical language, R, to summarize, analyze, and combine data to make appropriate visualizations and to conduct appropriate statistical tests.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#r-rstudio-and-the-tidyverse",
    "href": "index.html#r-rstudio-and-the-tidyverse",
    "title": "Applied Biostatistics",
    "section": "R, RStudio, and the tidyverse",
    "text": "R, RStudio, and the tidyverse\n\n\n\n\n\n\nThis image comes with permissions from Allison Horst, who makes tremendous aRt. If you appreciate her work, she would appreciate your support for Data for Black Lives\n\n\n\nWe will be using R (version 4.4.0 or above.) in this course, in the RStudio environment. My goal is to have you empowered to make figures, run analyses, and be well positioned for future work in R, with as much fun and as little pain as possible. RStudio is an environment and the tidyverse is a set of R packages that makes R’s powers more accessible without the need to learn a bunch of computer programming.\nSome of you might have experience with R and some may not. Some of this experience might be in tidyverse or not. There will be ups and downs — the frustration of not understanding and/or it not working and the joy of small successes. Remember to be patient, forgiving and kind to yourself, your peers, and me. Ask for help from the internet, your favorite LLM, your friends, your TAs, and your professor.\n\nR Installation\nBefore you can use R you must download and install it.\\(^*\\)  So, to get started, download R from CRAN, and follow the associated installation instructions (see below for detailed instructions for your system).\\(^*\\) This is not strictly true. You can use R online via posit cloud. This is a “freemium” service and the free plan is unlikely to meet your needs.\n\nPC install guideMac install guideLinux install guide\n\n\n\nIf you want a walk through, see Roger Peng’s tutorial on installing R on a PC youtube link here.\n“To install R on Windows, click the Download R for Windows link. Then click the base link. Next, click the first link at the top of the new page. This link should say something like Download R 4.4.2 for Windows except the 4.4.2 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you’ll need to have all of the appropriate administration privileges to install new software on your machine.”\n\nFrom Appendix A of Hands-On Programming With R – Grolemund (2014).\n\n\n\n\n\n\nIf you want a walk through, see Roger Peng’s tutorial on installing R on a mac].\n“To install R on a Mac, click the Download R for macOS link. Next, click on the [newest package link compatible with your computer]. An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I’ve never found a reason to change them. If your computer requires a password before installing new programs, you’ll need it here.”\n\nFrom Appendix A of Hands-On Programming With R – Grolemund (2014).\n\n\n\n\n\n\nR comes pre-installed on many Linux systems, but you’ll want the newest version of R if yours is out of date. The CRAN website provides files to build R from source on [Debian], Redhat, SUSE, and Ubuntu systems under the link “Download R for Linux.” Click the link and then follow the directory trail to the version of Linux you wish to install on. The exact installation procedure will vary depending on the Linux system you use. CRAN guides the process by grouping each set of source files with documentation or README files that explain how to install on your system.\n\nFrom Appendix A of Hands-On Programming With R – Grolemund (2014).\n\n\n\n\n\n\nAfter installing R download/update RStudio from here.\n\nAlternatively you can simply join the course via RStudioCloud. This could be desirable if you do not want to or have trouble doing this.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-is-this-book-and-how-will-we-use-it",
    "href": "index.html#what-is-this-book-and-how-will-we-use-it",
    "title": "Applied Biostatistics",
    "section": "What is this ‘book’ and how will we use it?",
    "text": "What is this ‘book’ and how will we use it?\nA fantastic feature of this book is that it does not stand alone. It is neither the entirety of the course content, nor is it all my idea. In addition from lifting from a few other courses online (with attribution), I also make heavy use of these texts:\n\nThe Analysis of Biological Data Third Edition (Whitlock & Schluter, 2020): I taught with this book for years. It is fantastic and shaped how I think about teaching Biostats. It has many useful resources available online. The writing is great, as are the examples. Most of my material originates here (although I occasionally do things a bit differently). Buy the latest edition.\nCalling Bullshit (Bergstrom & West, 2020): This book is not technical, but points to the big picture concerns of statisticians. It is very practical and well written. I will occasionally assign readings from this book, and/or point you to videos on their website. All readings will be made available for you, but you might want to buy a physical copy.\nFundamentals of Data Visualization (Wilke, 2019): This book is free online, and is very helpful for thinking about graphing data. In my view, graphing is among the most important skills in statistical reasoning, so I reference it regularly.\nR for Data Science (Grolemund & Wickham, 2018): This book is free online, and is very helpful for doing the sorts of things we do in R regularly. This is a great resource.\nThe storytelling with data podcast is a fantastic data viz podcast. Be sure to check out Cole Nussbaumer Knaflic’s books too!",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-will-this-term-work-look",
    "href": "index.html#how-will-this-term-work-look",
    "title": "Applied Biostatistics",
    "section": "How will this term work / look?",
    "text": "How will this term work / look?\n\nPrep for ‘class’. This class is flipped with asynchronous content delivery and synchronous meetings.\n\nBe sure to look over the assigned readings and/or videos, and complete the short low-stakes homework BEFORE each course.\n\nDuring class time, I will address questions make announcements, and get you started on in-class work. The TA & I will bounce around your breakout rooms to provide help and check-in. If you cannot make the class, you could do this on your own time without help, but we do not recommend this as a class strategy.\n\nThe help of your classmates and the environment they create is one of the best parts of this class. Help each other.\n\nIn addition to low stakes work before and in class, there will be a few more intense assignments, some collaborative projects, some in class exams, and a summative project as the term ends.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#the-use-of-large-language-models",
    "href": "index.html#the-use-of-large-language-models",
    "title": "Applied Biostatistics",
    "section": "The Use of Large Language Models",
    "text": "The Use of Large Language Models\nWe are in the early days of a truly disruptive technology. Large Language Models (LLMs) like ChatGPT and Claude are transforming how we work and learn. While the impact of these tools on future employment, expertise, and citizenry is yet to be settled, it seems clear that no one will hire you to copy and paste AI-generated output. At the same time, no one will hire you to ignore this technology. Success lies in learning how to critically evaluate and work with LLMs—to validate their output, improve your own understanding, and create high-quality results. Subject-level expertise, in conjunction with strong skills in working with AI, will be essential for the foreseeable future.\n\nYou can use LLMs to learn things or avoid learning things. Choose wisely.\n\nLearning from AI and having it help you solve problems will allow you all to do better and learn more than people have been able to do previously. Using AI to avoid learning – e.g. having it write or code for you without you thinking/learning will always come back to bite you in the ass.\nWhile you are ultimately in charge of your learning, I will provide plenty of opportunities for in-class, computer-free efforts to show your mastery of the subject. I will also provide guidance on individual assignments about the appropriate use of AI to help maximize the impact of the assignment on your learning.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#the-path-through-the-term",
    "href": "index.html#the-path-through-the-term",
    "title": "Applied Biostatistics",
    "section": "The path through the term",
    "text": "The path through the term\nI start by assuming you know nothing about R or statistics to start (I know this assumption is wrong – many of you all know a lot!). From this humble beginning I aim to leave you with the skills to conduct standard statistical analyses, and the understanding of statistics and the ability to go beyond what we have learned. We take the following path in Figure 1, below:\n\n\n\n\n\n\n\n\nFigure 1: Our journey through biostatistics begins with (1) gaining comfort in R, then moves on to (2) describing data and (3) considering sampling and uncertainty. Next, we (4) introduce null hypothesis significance testing, (5) build models, and (6) address more advanced topics (aka “the big lake of statistics”, aka Lake Isabella).",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Applied Biostatistics",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nStudents\nFirst and foremost, I would like to thank the more than 500 students who have taken my Applied Biostatistics course. Students provide the most important feedback on whether a particular pedagogical approach is effective. While not every experiment succeeds, I am incredibly grateful to each student who has helped me learn what works and what doesn’t as they engaged with the material.\n\n\nTeaching Assistants (TAs)\nI have been fortunate to work with outstanding graduate teaching assistants over the past ten years:\n\nDerek Nedveck: Derek played a key role in helping me establish the course during its early years.\nGerman Vargas Gutierrez: A highly skilled statistician, German’s assistance was invaluable in refining the course a few years into its development.\nChaochih Liu: A brilliant programmer, Chaochih contributed greatly to the course’s organization and structure.\nHusain Agha: Husain has remarkable insights into statistics, genetics, and teaching. My work has greatly benefited from bouncing ideas off him.\nBrooke Kern: Brooke was not only an exceptional TA but also a valuable collaborator. Much of the data in this book is drawn from her dissertation research.\n\n\n\n\n\n\n\n\n\n\nFigure 2: My incredible TAs who have all helped shape this material.\n\n\n\n\n\n\n\nCollaborators\nBrooke Kern, Dave Moeller and Shelley Sianta have generated much of the data in this book and have been patient with my delays in turning around our research during teaching times. Dave also provided nearly every picture in this book.\n\n\nTeaching Colleagues\nI have learned a lot about statistics and how to teach it from John Fieberg. His book, Statistics for Ecologists is fantastic! I am also deeply indebted to Fumi Katagiri who began this course and worked through a lot of it before I arrived at UMN, and who thinks deeply about stats and how to teach it.\n\n\nPeople who provided comments\nJohn Rotenberry, and Ruth Shaw have provided helpful comments!\n\n\nUnknowing contributors\nThe online community of statistics and R teaching is an amazing place. I have borrowed heavily from the many amazing free resources. Here are the most critical:\n\nAllison Horst has fantastic illustrations for statistics that she makes freely available.\nPeter D.R. Higgins has created a truly marvelous book – Reproducible Medical Research With R (Higgins (2024)). I have learned a lot and stolen some teaching tricks from this work.\nJenny Bryan has helped me think about getting students able to do things in R well and quickly. Her book, STAT 545: Data wrangling, exploration, and analysis with R (Bryan (2020)), is a classic.\n\n\n\n\n\nBergstrom, C. T., & West, J. D. (2020). Calling bullshit: The art of skepticism in a data-driven world. Random House.\n\n\nBryan, J. J. (2020). STAT 545: Data wrangling, exploration, and analysis with r. Bookdown. https://stat545.com\n\n\nGrolemund, G. (2014). Hands-on programming with r: Write your own functions and simulations. \" O’Reilly Media, Inc.\".\n\n\nGrolemund, G., & Wickham, H. (2018). R for data science.\n\n\nHiggins, P. D. R. (2024). Reproducible medical research with r. Bookdown. https://bookdown.org/pdr_higgins/rmrwr/\n\n\nWhitlock, M. C., & Schluter, D. (2020). The analysis of biological data (Third). Macmillan.\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: A primer on making informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "book_sections/clarkia_and_its_data/clarkia_and_its_data.html",
    "href": "book_sections/clarkia_and_its_data/clarkia_and_its_data.html",
    "title": "Motivating biology and datasets",
    "section": "",
    "text": "RILs between sympatric and allopatric parviflora\nWouldn’t it be cool if, at this stage, the populations could evolve a mechanism to preferentially mate with their own kind? The adaptive evolution of avoiding mating with a closely related species—a process known as reinforcement—does just that. However, the evolution of reinforcement is complex and has only been conclusively documented in a handful of cases.\nDave Moeller and colleagues (including me) have been investigating one potential case of reinforcement. Clarkia xantiana subspecies parviflora (hereafter parviflora) is an annual flowering plant native to California. Unlike its outcrossing sister subspecies, Clarkia xantiana subspecies xantiana (hereafter xantiana), parviflora predominantly reproduces through self-pollination.\nNot all populations of parviflora self-fertilize at the same frequency. Dave has observed that populations sympatric with (i.e., occurring in the same area as) xantiana appear more likely to self-fertilize than allopatric populations (Figure 1). Over the past few years, we have conducted numerous studies to evaluate the hypothesis that this increased rate of self-fertilization has evolved via reinforcement as a mechanism to avoid hybridizing with xantiana.\nThroughout this book, I will use data related to the topic of divergence, speciation, and reinforcement between Clarkia subspecies as a path through biostatistics. I hope that this approach allows you to engage with the statistics while not having to keep pace with a bunch of different biological examples. Below, I introduce the major datasets that we will explore.\nFigure 2: Making a RIL population: A cross between individuals from two populations is followed by multiple generations of self-fertilization. As a result, each “line” becomes a mosaic of ancestry blocks inherited from either initial parent of the RIL. The figure above (from Behrouzi & Wit (2017)) illustrates this process, with the original parental chromosome segments depicted in green and red.\nTo investigate which traits, if any, help parviflora populations sympatric with xantiana avoid hybridization, Dave generated Recombinant Inbred Lines (RILs). To do so, he crossed a parviflora plant from “Sawmill Road”—a population sympatric with xantiana—with a parviflora plant from “Long Valley,” far from any xantiana populations. After this initial cross, lines were self-fertilized for eight generations. This process breaks up and shuffles genetic variation from the two parental populations while ensuring each line is genetically stable.\nBy setting these RILs out in the field and observing how many pollinators visited each line, we hope to identify which traits influence pollinator visitation and ultimately hybridization. Because parviflora plants often self-pollinate and because pollinators effectively transfer pollen from the plentiful xantiana plants to parviflora, we assume that greater pollinator visitation corresponds to higher hybrid seed set. However, we will test this assumption!!!",
    "crumbs": [
      "Motivating biology and datasets"
    ]
  },
  {
    "objectID": "book_sections/clarkia_and_its_data/clarkia_and_its_data.html#rils-between-sympatric-and-allopatric-parviflora",
    "href": "book_sections/clarkia_and_its_data/clarkia_and_its_data.html#rils-between-sympatric-and-allopatric-parviflora",
    "title": "Motivating biology and datasets",
    "section": "",
    "text": "RIL Data\nBelow is the RIL dataset. You can learn about the columns (in the Data dictionary tab) and browse the data (in the Data set tab). The full data are available at\nthis link. Aside from pollinator visitation and hybrid seed set, all phenotypes measured come not from the plants in the field, but means from replicates of the genotype grown in the greenhouse.\n\nRIL variationData DictionaryData set\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: An illustration o the variabiltiy in the recombinant inbred lines. Pictures by Taz Mueller and arranged by Brooke Kern.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable_Name\nData_Type\nDescription\n\n\n\n\nril\nCategorical (Factor/String)\nIdentifier for Recombinant Inbred Line (RIL). This is the 'genotype'.\n\n\nlocation\nCategorical (Factor/String)\nField site where the plant was grown.\n\n\nprop_hybrid\nNumeric (discrete)\nProportion of genotyped seeds that were hybrids (see num_hybrid and offspring_genotyped for more information).\n\n\nmean_visits\nNumeric\nAverage number of pollinator visits per plant over a 15-minute observation.\n\n\ngrowth_rate\nNumeric\nGrowth rate of the plant.\n\n\npetal_color\nCategorical (Binary)\nPetal color phenotype (in this case 'pink' or 'white').\n\n\npetal_area_mm\nNumeric\nDate when the first flower opened (in Julian days, i.e., days since New Year's).\n\n\ndate_first_flw\nDate\nNode position of the first flower on the stem.\n\n\nnode_first_flw\nNumeric\nPetal area measured in square millimeters (mm²).\n\n\npetal_perim_mm\nNumeric\nPetal perimeter measured in millimeters (mm).\n\n\nasd_mm\nNumeric\nThe Anther-Stigma Distance (ASD) is the linear distance between the closest anther (the floral part that releases pollen) and the stigma (the floral part that accepts pollen) in a flower, measured in millimeters (mm). The smaller this distance, the more opportunity for self-fertilization.\n\n\nprotandry\nNumeric\nDegree of protandry (e.g., time difference between male and female phase) measured in days. More protandry means more outcrossing.\n\n\nstem_dia_mm\nNumeric\nStem diameter measured in millimeters (mm).\n\n\nlwc\nNumeric\nLeaf water content (LWC).\n\n\ncrossDir\nCategorical (Binary)\nCross direction\n\n\nnum_hybrid\nNumeric (discrete)\nThe number ofseeds that where hybrid.\n\n\noffspring_genotyped\nNumeric (discrete)\nThe number of seeds genotyped.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRIL Hybridization Data\nBelow is the hybridization dataset. For each plant in the field we genotyped eight seeds at species-specific markers to identify if they were the product of hybridization with xantiana. The phenotypes belong to the genotype of the maternal plant (i.e. they are the same as those in the pollinator visitation data set). I include data at both the level of the seed and a summary at the level of the maternal plant.\n\n\nRIL Combined Data\n\n\n\n\nBehrouzi, P., & Wit, E. (2017). Detecting epistatic selection with partially observed genotype data using copula graphical models. Journal of the Royal Statistical Society: Series C (Applied Statistics), 68. https://doi.org/10.1111/rssc.12287",
    "crumbs": [
      "Motivating biology and datasets"
    ]
  },
  {
    "objectID": "book_sections/example_mini/varType.html",
    "href": "book_sections/example_mini/varType.html",
    "title": "Types of Variables",
    "section": "",
    "text": "Explanatory and Response Variables\nAlthough these taxa hybridize in nature, they remain quite distinct, even in areas of sympatry where they exchange genes.\nDave Moeller and his colleagues (including me) have been studying this species for decades. Their research addresses fundamental questions in evolution, such as:\nTo answer these big and exciting questions, Dave and his collaborators must break them down into smaller, direct scientific studies that can be addressed through a combination of experiments and observations. To conduct such studies, we must map these complex ideas onto measurable variables.\nFor example, rather than directly comparing the flower images in Figure 1, we simplify these flowers into variables that summarize them. For instance, we could represent a flower using a set of variables such as flower color, petal length, the distance between stigma and style, etc.\nDave and his team have conducted numerous studies to tackle these big questions. In most cases, they examine how the value of a response variable — the outcome we aim to understand — changes with different values of one or more explanatory variables (also called predictor or independent variables), which are thought to influence or be associated with the biological process of interest.\nUnderstanding the distinction between explanatory and response variables is crucial for framing hypotheses, designing experiments, and interpreting statistical results. However, this distinction often depends on how the research question is framed and can even vary within a single study. For example, in a recent study on predictors of pollinator visitation in parviflora",
    "crumbs": [
      "Types of Variables"
    ]
  },
  {
    "objectID": "book_sections/example_mini/varType.html#explanatory-and-response-variables",
    "href": "book_sections/example_mini/varType.html#explanatory-and-response-variables",
    "title": "Types of Variables",
    "section": "",
    "text": "We first aimed to identify which loci in the genome predicted flower color and petal length in parviflora. Here, genotype was the explanatory variable, while the floral attributes (petal color and petal length) were the response variables.\nWe then asked whether certain floral attributes (petal color and petal length) predicted pollinator visitation to parviflora plants. In this case, the floral attributes became the explanatory variables, and pollinator visitation was the response variable.",
    "crumbs": [
      "Types of Variables"
    ]
  },
  {
    "objectID": "book_sections/example_mini/varType.html#types-of-variables",
    "href": "book_sections/example_mini/varType.html#types-of-variables",
    "title": "Types of Variables",
    "section": "Types of Variables",
    "text": "Types of Variables\n\n\n\n\n\n\n\n\n\nFigure 2: Which type of variable is color? Some variables (like color) can be treated as either categorical or continuous depending on the question. Because most parviflora plants are either pink or white, we treat color as a binary categorical variable. But, as shown above, color can be measured and analyzed quantiatively as well.\n\n\n\n\n\n# INSERT POLINATOR OBSERVATION VIDEO \n\nVariables come in different flavors, and knowing the flavor of a variable is key to choosing appropriate summary statistics, data visualizations, and statistical models. Our parviflora pollinator visitation example above included both major types of variables (Figure 1):\n\nNumeric variables are quantitative and have magnitude. For instance, we measured pollinator visits as the number of times a pollinator visited a flower during a [5-minute observation period], and petal length in centimeters.\n\nCategorical variables are qualitative. In our example, flower color and genotype were treated as categorical variables.\n\nLike much of stats – the line between these types of variables is blurry. For example, we often treat color as a category, but color can be measured quantitatively (Figure 2). So depending on our question we may want to treat color as either a numeric or categorical variable.\n\nNot All Numbers Are Numeric. For example, a gene ID may be represented as a number, but it is an arbitrary label rather than a measurement. Similarly, in our Clarkia studies, some sites were identified by numbers (e.g., Site 22 or Site 100). However, Site 22 is not “less than” Site 100 — these are categorical variables, despite being represented numerically.\n\nWithin these two categories are further sub-flavors which allow us to further refine our statistical approach:\n\nTypes of Numeric Variables\n\n\n\n\n\n\n\n\n\nFigure 3: Types of numeric variables.  A discrete variable: Xantiana flowers with four, five or six petals (photo courtesy of Dave Moeller).   A continuous variable: Parviflora petal whose length is being measured. Image from The University and Jepson Herbaria University of California, Berkeley. Copyright from ©2020 Chris Winchell. (image link)\n\n\n\n\nNumeric variables can be categorized into two main types:\n\nDiscrete variables come in chunks. For instance, flowers receive zero, one, two, three, and so on, pollinators. Pollinators do not come in fractions, making this variable inherently discrete.\nContinuous variables can take any value within a range. Classic examples include height, weight, and temperature. In our example, petal length is a continuous variable because it can be measured to any level of precision within its range.\n\n\nSubtle Distinctions and Blurry Boundaries. The two cases above represent pretty clear distinctions between discrete and continuous variables, but sometimes such distinctions are more subtle.\nConsider the number of pollinators—these cannot be fractional, but the number of pollinators per minute can be fractional. There are other similarly blurry cases. For example, time to first flower is inherently continuous, but we often check on flowers only once per day, so it is measured as discrete. Similarly, in human studies, age is usually reported in whole months or years (discrete), rather than on the more continuous scale of fractional seconds. In such cases, the appropriate question is not “is my data discrete or continuous?” but rather “what process generated my data? and what statistical distribution do the data follow?\n\n\n\nCategorical variables\n\n\n\n\n\n\n\n\n\nFigure 4: Species is a categorical variable: The Clarkia specialist – Clarkia Evening Bee, (Hesperapis regularis) on a Clarkia flower. Shared by © Gene H under CC BY-NC 4.0 copyright on iNaturalist. In our Clarkia research, pollinator is usually nominal (that is which bee species), but is sometimes binary (Clarkia specialist, or non-specialist), and sometimes ordinal (e.g. frequent pollinator, rare pollinator, never pollinator).\n\n\n\n\nCategorical variables are qualitative, and include, nominal, binary, and ordinal variables.\n\nNominal variables cannot be ordered and have names – like sample ID, species, study site etc…\n\nBinary variables are a type of nominal variable with only two options (or for which we only consider two options. Alive/dead, pass/fail, on/off are classic binary variables). In our example of pollinator visitation in parviflora, we considered only two flower colors (pink/white) so flower color in this case is binary.\n\nOrdinal variables can be ordered, but do not correspond to a magnitude. For example, bronze, silver and gold medals in the Olympics are ranked from best to worst, but first is not some reliable distance away from second or third etc… In our pollinator example, we often may wish to distinguish between frequent pollinators (e.g. specialist bees, Figure 4), common but less frequent pollinators (e.g. non-specialist bees), and rare/incidental pollinators (e.g. flies).",
    "crumbs": [
      "Types of Variables"
    ]
  },
  {
    "objectID": "book_sections/example_mini/varType.html#closing-resources",
    "href": "book_sections/example_mini/varType.html#closing-resources",
    "title": "Types of Variables",
    "section": "Closing Resources",
    "text": "Closing Resources\n\nSummary\nUnderstanding the types of variables in our data can help us translate complex biological questions into measurable data that can be evaluated with the statistical tools we develop in this book. Variables can be categorized as numeric or categorical, and further subdivided into types like discrete, continuous, nominal, binary, or ordinal. These classifications influence how we summarize, visualize, analyze, and modelize our data.\n\n\nChatbot tutor\nPlease interact with this custom chatbot (link here) I have made to help you with this chapter. I suggest interacting with at least ten back-and-forths to ramp up and then stopping when you feel like you’ve got what you needed from it.\n\n\nPractice Questions\nTry the questions below! Likert scales look like this:- How do you feel about Clarkia? (1) Love it  (2) Like it  (3) Don’t care  (4) Do not like (5) Hate it\n\nQ1) In a species with pink or white flowers, flower color is a special kind of categorical variable known as a ___ variable NominalBinaryOrdinalBimodal\n\n\nClick here for explanation\n\nThis was a little tricky! The correct answer is Binary, because there are only two possible values. If you picked either “nominal” or “bimodal,” you’re pretty close and definitely thinking along the right path, but not quite there! So let’s walk through these “not quite right” answers:\n\nNominal: Petal color is nominal in the sense that “pink” isn’t greater or lesser than “white”—the categories have no natural order. But because there are only two options here, the more specific (and better) description is Binary.\nBimodal: A bimodal distribution refers to a numeric variable that has two distinct peaks or clusters. If we had measured flower color quantitatively—say, by recording percent reflectance at 550 nm—and the data clustered around two values (say, “mostly pink” vs. “mostly white”), then the distribution would be bimodal. (But even then, we’d probably simplify it to binary for analysis.)\n\nIf you answered “ordinal,” you should probably take another look at the chapter—ordinal variables have a meaningful order, like “small,” “medium,” and “large.”\n\n.\nQ2) Which of these variables is best described as continuous? Flower color (pink, white)Petal lengthNumber of flowers on a plant\nQ3) The number of offspring produced by a single animal in one breeding season is: BinaryContinuousDiscrete\nQ4) TRUE or FALSE: Populations of Clarkia that we named 100 and 22 are numeric TRUEFALSE.\nQ5) TRUE or FALSE: A variable on a “Likert scale” (see margin for details) is clearly numeric TRUEFALSE.\n\n\nClick here for explanation\n\nThe word “clearly” is the key clue here. A Likert scale (like rating agreement from “Strongly disagree” to “Strongly agree”) is based on numbers (e.g., 1, 2, 3, 4, 5), but those numbers represent ordered categories, not truly continuous or clearly numeric values.\nIn other words, while you can treat Likert scale data like numbers sometimes (e.g., calculating averages), the numbers themselves are standing in for categories with an order—not for measured quantities along a true number line. So while you might have seen Likert data analyzed using means, t-tests, or even regressions—treating them like numeric variables—this is a common (and sometimes reasonable) modeling shortcut. Conceptually, Likert data are still clearly ordinal: they are ordered categories, not continuous measurements.\nIf you missed this, don’t worry — Likert scales can be a little tricky because they look numeric. But always pay close attention to what the numbers mean. If they’re just labeling ordered choices (rather than measuring something truly continuous, like height or weight), the variable is ordinal categorical, not clearly numeric.\n\n.\nQ6) The variable, kingdom (corresponding to one of the six kingdoms of life), is a ___ variable NominalBinaryOrdinalDiscrete\nQ7) TRUE of FALSE: A continuous variable can never be modeled as discrete and vice versa TRUEFALSE\n\n\n\n\nGlossary of Terms\n\n\nVariable: A characteristic or attribute that can take on different values or categories in a dataset.\n\nExplanatory Variable: Also known as a predictor or independent variable, this is a variable that is thought to influence or explain the variation in another variable.\nResponse Variable: Also known as a dependent variable, this is the outcome or effect being studied, which changes in response to the explanatory variable.\n\n\n\n\nNumeric Variable: A variable that represents measurable quantities and has magnitude, either as counts (discrete) or as continuous values.\n\nDiscrete Variable: A numeric variable that represents distinct, separate values or counts (e.g., number of pollinators).\nContinuous Variable: A numeric variable that can take any value within a range and is measured with precision (e.g., petal length).\n\n\n\n\nCategorical Variable: A variable that represents categories or groups and is qualitative in nature.\n\nNominal Variable: A categorical variable without an inherent order (e.g., flower species or study site).\nBinary Variable: A nominal variable with only two possible categories (e.g., alive/dead, pink/white).\nOrdinal Variable: A categorical variable with a meaningful order, but without measurable distances between levels (e.g., gold, silver, bronze).",
    "crumbs": [
      "Types of Variables"
    ]
  },
  {
    "objectID": "book_sections/getting_started.html",
    "href": "book_sections/getting_started.html",
    "title": "1. Getting started with R",
    "section": "",
    "text": "What is R? What is RStudio?\nR is a computer program built for data analysis. As opposed to GUIs, like Excel, or click-based stats programs, R is focused on writing and sharing scripts. This enables us to be shared and replicate analyses, ensuring that data manipulation occurs in a script. This practice both preserving the integrity of the original data, while providing tremendous flexibility. R has become the computer language of choice for most statistical work because it’s free, allows for reproducible analyses, makes great figures, and has many “packages” that support the integration of novel statistical approaches. In a recent paper, we used R to analyze hundreds of Clarkia genomes and learn about the (Figure 1 from Sianta et al. (2024)). RStudio is an Integrated Development Environment (IDE)—a nice setup to interact with R and make it easier to use.",
    "crumbs": [
      "1. Getting started with R"
    ]
  },
  {
    "objectID": "book_sections/getting_started.html#what-is-r-what-is-rstudio",
    "href": "book_sections/getting_started.html#what-is-r-what-is-rstudio",
    "title": "1. Getting started with R",
    "section": "",
    "text": "More precisely, R is a programming language that runs computations, while RStudio is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools. So just as the way of having access to a speedometer, rearview mirrors, and a navigation system makes driving much easier, using RStudio’s interface makes using R much easier as well.\n— From Statistical Inference via Data Science: A ModernDive into R and the Tidyverse (Ismay & Kim, 2019)",
    "crumbs": [
      "1. Getting started with R"
    ]
  },
  {
    "objectID": "book_sections/getting_started.html#the-shortest-introduction-to-r",
    "href": "book_sections/getting_started.html#the-shortest-introduction-to-r",
    "title": "1. Getting started with R",
    "section": "The Shortest Introduction to R",
    "text": "The Shortest Introduction to R\nBefore opening RStudio, let’s get familiar with two key ays we use R – (1) Using R as a calculator, and (2) Storing information by assigning values to variables.\nR can perform simple (or complex) calculations. For example, entering 1 + 1 returns 2, and entering 2^3 (two raised to the power of three) returns 8. Try it yourself by running the code below, and then experiment with other simple calculations.Math in R: See posit's recipe for using R as a calculator for more detail.\nCommenting code The hash, #, tells R to stop reading your code. This allows you to “comment” your code – keeping notes to yourself and other readers about what the code is doing. Commenting your code is very valuable and you should do it often!Commenting code The hash, #, tells R to stop reading your code. This allows you to “comment” your code – keeping notes to yourself and other readers about what the code is doing. Commenting your code is very valuable and you should do it often!\nChallengeSolution\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nStoring values in variables allows for efficient (and less error-prone) analyses, while paving the way to more complex calculations. In R, we assign values to variables using the assignment operator, &lt;-. For example, to store the value 1 in a variable named x, type x &lt;- 1. Now, 2 * x will return 2.\n\n\nx &lt;- 1 # Assign 1 to x\n2 *  x # Multiply x by 2\n\n[1] 2\n\nBut R must “know” something before it can “remember” it. The code below aims to set y equal to five, and see what y plus one is (it should be six). However, it returns an error. Run the code to see the error message, then fix it!\n\nChallengeSolution\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint\n\nR reads and executes each line of code sequentially, from top to bottom. Think about what y + 1 means to R if it hasn’t seen a definition of y yet.\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nHint\n\nIn R, variables must be defined before they are used. When you try to use y + 1 before assigning a value to y, R throws an error because it doesn’t know what y is yet. When we switch the order—assigning y &lt;- 5 before using y + 1—R understands the command and evaluates it properly.\n\n\n\n\nNow, try assigning different numbers to x and y, or even using them together in a calculation, such as x + y. Understanding this concept of assigning values is critical to understanding how to use R.",
    "crumbs": [
      "1. Getting started with R"
    ]
  },
  {
    "objectID": "book_sections/getting_started.html#lets-get-started-with-r",
    "href": "book_sections/getting_started.html#lets-get-started-with-r",
    "title": "1. Getting started with R",
    "section": "Let’s get started with R",
    "text": "Let’s get started with R\nThe following sections introduce the very basics of R including:\n\nFunctions and vectors in R.\n\nLoading packages and data into R.\n\nData types in R.\n\nAn orientation to RStudio.\n\nThen we summarize the chapter, present practice questions, a glossary, a review of R functions and R packages introduced, and provide links to additional resources.\n\n\n\n\nIsmay, C., & Kim, A. Y. (2019). Statistical inference via data science: A ModernDive into r and the tidyverse. CRC Press.\n\n\nSianta, S. A., Moeller, D. A., & Brandvain, Y. (2024). The extent of introgression between incipient &lt;i&gt;clarkia&lt;/i&gt; species is determined by temporal environmental variation and mating system. Proceedings of the National Academy of Sciences, 121(12), e2316008121. https://doi.org/10.1073/pnas.2316008121",
    "crumbs": [
      "1. Getting started with R"
    ]
  },
  {
    "objectID": "book_sections/getting_started/functions_and_vectors.html",
    "href": "book_sections/getting_started/functions_and_vectors.html",
    "title": "• 1. Functions and vectors",
    "section": "",
    "text": "R Functions\nR comes with tons of built-in functions that do everything from basic math to advanced statistical modeling. So not only can we calculate the mean and variance in Clarkia xantiana petal lengths with the mean() and var() functions, respectively, but we can test the null hypothesis that mean petal size in xantiana is equal to that of parviflora with the t.test() function. Functions are the foundation of how we do things in R – they save time and ensure consistency across your analyses.\nFunctions take arguments, which we put in parentheses. When typing sqrt(25), sqrt() is the function, 25 is the argument, and 5 is the output.\nFunctions can take multiple arguments: If you don’t specify them all, R will either tell you to provide them, or assumes default values. For example, the log function defaults to the natural log (base e), so log(1000) returns 6.908. If you want the logarithm with base 10, you need to specify it explicitly as log(1000, 10), which returns 3. Note that argument order matters:—log(10, 1000) returns 0.3333333, while log(1000, 10) returns 3.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Functions and vectors"
    ]
  },
  {
    "objectID": "book_sections/getting_started/functions_and_vectors.html#r-functions",
    "href": "book_sections/getting_started/functions_and_vectors.html#r-functions",
    "title": "• 1. Functions and vectors",
    "section": "",
    "text": "R functions: See posit's recipe for R functions for more detail.\n\n\n\n\n# Natural log of 1000\nlog(1000)             \n\n[1] 6.907755\n\n\n\n\n# Log base 1000 of 10\nlog(1000, base = 10)  \n\n[1] 3\n\n\nTips for using functions in R\n\nUse named arguments in functions.\nFor example, typing log(1000, base = 10) makes what each value represents obvious (improving code readability), and allows flexibility in argument order (e.g. log(base = 10, 1000) gives the same value as log(1000, base = 10)). Thus, using named arguments makes your code readable and robust.\n\n\nUse = to assign arguments in functions\nWhen specifying arguments inside a function, always use = (e.g., log(1000, base = 10)). Do not use &lt;-, which is for assigning values to variables. Otherwise, R might mistakenly store the argument as a variable, leading to unexpected results.\n\n\nPipe together functions with |&gt;\nThe pipe, |&gt;, provides a clean way to pass the output of one function into another. For example, we can find the square root of the \\(\\text{log}_{10}\\) of 1000, rounded to two decimal places, as follows:\n\nlog(1000, base = 10)   |&gt;  \n    sqrt()             |&gt;  \n    round(digits = 2)\n\n[1] 1.73\n\n\nNotice that we did not explicitly provide an argument to sqrt() — it simply used the output of log(1000, base = 10). Similarly, the round() function then rounded the square root of 3 to two decimal places.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Functions and vectors"
    ]
  },
  {
    "objectID": "book_sections/getting_started/functions_and_vectors.html#working-with-vectors",
    "href": "book_sections/getting_started/functions_and_vectors.html#working-with-vectors",
    "title": "• 1. Functions and vectors",
    "section": "Working with vectors",
    "text": "Working with vectors\nIf we observed one Clarkia plant with one flower, a second with two flowers, a third with three flowers, and a fourth with two flowers, we could find the mean number of flowers as (1 + 2 + 3 + 2)/4 = 2, but this would be tedious and error-prone. It would be easier to store these values in an ordered sequence of values (called a vector) and then use the (mean()) function.\nVectors are the primary way that data is stored in R—even more complex data structures are often built from vectors. We create vectors with the combine function, c(), which takes arguments that are the values in the vector.\n\n# A vector of flower numbers\n  # 1st plant has one flower\n  # 2nd plant has two flowers\n  # 3rd plant has three flowers\n  # 4th plant has two flowers\nnum_flowers &lt;- c(1, 2, 3, 2)  # Create a vector for number of flowers per plant\nmean(num_flowers) # finding the mean flower number\n\n[1] 2\n\n\n\n\n# If each flower produces four petals  \nnum_petals &lt;- 4 * num_flowers\nnum_petals\n\n[1]  4  8 12  8\n\n\n# If we wanted the log_2 of petal number \nlog(num_petals, base = 2) |&gt;\n  round(digits = 3)\n\n[1] 2.000 3.000 3.585 3.000\n\n\n\nVariable assignment can be optional: In the code, I assigned observations to the vector, num_flowers, and then found the mean. But we could have skipped variable assignment—variable assignment — mean(c(1, 2, 3, 2)) also returns 2.\nThere are two good reasons not to skip variable assignment:\n\nVariable assignment makes code easier to understand. If I revisited my code in weeks I would know what the mean of this vector meant.\nVariable assignment allows us to easily reuse the information For example, below I can easily find the mean petal number.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Functions and vectors"
    ]
  },
  {
    "objectID": "book_sections/getting_started/loading_packages_and_data.html",
    "href": "book_sections/getting_started/loading_packages_and_data.html",
    "title": "• 1. Load packages and data",
    "section": "",
    "text": "R packages\nWhile R has many built-in functions, packages provide even more functions to extend R’s capabilities. Packages can offer alternative (often more efficient and user-friendly) approaches to tasks that can be done with base R functions, or they can enable entirely new functionality that is not included in base R at all. In fact, R packages are a major way that the latest statistical and computational methods in various fields are shared with practitioners.\nBelow I introduce the readr, and dplyr packages. Because these packages are so useful for streamlining data import, manipulation, and cleaning, I use them in nearly every R project. I also introduce the conflicted package, which identifies any functions with shared names across packages, and allows us to tell R which function we mean when more than one function has the same name.\nInstall a package the first time you use it The first time you need a package, install it with the install.packages() function. Here the argument is the package (or vector of packages) you want to install. So, to install the packages above, type:\n# We do this the first time we need a package.\ninstall.packages(c(\"readr\", \"dplyr\", \"conflicted\"))\nLoad installed packages every time you open RStudio You only install a package once, but you must use the library() function, as I demonstrate below, to load installed packages every time you open R.\n# We do this every time we open R and want to use these packages.\nlibrary(conflicted)\nlibrary(readr)\nlibrary(dplyr)",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Load packages and data"
    ]
  },
  {
    "objectID": "book_sections/getting_started/loading_packages_and_data.html#reading-data-into-r",
    "href": "book_sections/getting_started/loading_packages_and_data.html#reading-data-into-r",
    "title": "• 1. Load packages and data",
    "section": "Reading data into R",
    "text": "Reading data into R\nRather than typing large datasets into R, we usually want to read in data that is already stored somewhere. For now, we will load data saved as a csv file from the internet with the read_csv(link) structure from the readr package. Later, we will revisit the challenge of importing data from other file types and locations into R.\n\n\nLoading data: See posit's recipe for importing data for more detail. Note also that read.csv() is a base R function similar to read_csv(), but it behaves a bit differently – for example it reads data in as a dataframe, not a tibble.\nBelow, I show an example of reading pollinator visitation data from a link on my GitHub. After loading a dataset, you can see the first ten lines and all the columns that fit by simply typing its name. Alternatively, the View() function opens up the full spreadsheet for you to peruse.\n\nril_link &lt;- \"https://raw.githubusercontent.com/ybrandvain/datasets/refs/heads/master/clarkia_rils.csv\"\nril_data &lt;- readr::read_csv(ril_link)\nril_data\n\n# A tibble: 593 × 17\n   ril   location prop_hybrid mean_visits growth_rate petal_color petal_area_mm\n   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;               &lt;dbl&gt;\n 1 A1    GC             0           0     1.272       white                44.0\n 2 A100  GC             0.125       0.188 1.448       pink                 55.8\n 3 A102  GC             0.25        0.25  1.8O        pink                 51.7\n 4 A104  GC             0           0     0.816       white                57.3\n 5 A106  GC             0           0     0.728       white                68.6\n 6 A107  GC             0.125       0     1.764       pink                 66.3\n 7 A108  GC            NA          NA     1.584       &lt;NA&gt;                 51.5\n 8 A109  GC             0           0     1.476       white                48.1\n 9 A111  GC             0          NA     1.144       white                51.6\n10 A112  GC             0.25        0     1           white                89.8\n# ℹ 583 more rows\n# ℹ 10 more variables: date_first_flw &lt;dbl&gt;, node_first_flw &lt;dbl&gt;,\n#   petal_perim_mm &lt;dbl&gt;, asd_mm &lt;dbl&gt;, protandry &lt;dbl&gt;, stem_dia_mm &lt;dbl&gt;,\n#   lwc &lt;dbl&gt;, crossDir &lt;chr&gt;, num_hybrid &lt;dbl&gt;, offspring_genotyped &lt;dbl&gt;\n\n\n\n\n\n\npackage::function() format: I read in the data with the read_csv() function in the readr package by typing: readr::read_csv(), but typing read_csv() gives the same result. The package::function() format comes in handy when two functions in different packages have the same name.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Load packages and data"
    ]
  },
  {
    "objectID": "book_sections/getting_started/data_types.html",
    "href": "book_sections/getting_started/data_types.html",
    "title": "• 1. Data types in R",
    "section": "",
    "text": "Motivating scenario: You have loaded data into R and are curious about what “types” of data R thinks it is working with.\nLearning goals: By the end of this sub-chapter you should be able to\n\nList the different types of variables that R can keep in a vector.\n\nIdentify which type of variable is in a given column.\n\nAsk logical questions of the data to make a logical vector.\n\n\n\n\nR handles different types of data in specific ways. Understanding these data types is crucial because what you can do with your data depends on how R interprets it. For example, although you know that 1 + \"two\" equals 3, R cannot add a number and a word. So, to use R effectively, you will need to make sure the type of data R has in memory matches the type it needs to have to do what you want. This will also help you understand R’s error messages and confusing results when things don’t work as expected.\nLooking back at the pollinator visitation dataset we loaded above, we see that (if you read it in with read_csv()) R tells you the class of each column before showing you its first few values. In that dataset, columns one, two, five, six, and fifteen (note R provides a peek of the first few variables — in this case, seven — and then provides the names and data type for the rest) — location, ril, growth_rate, and petal_color — are of class &lt;chr&gt;, while all other columns contain numbers (data of class &lt;dbl&gt;). What does this mean? Well it tells you what type of data R thinks is in that column. Here are the most common options:\n\nNumeric: Numbers, including doubles (&lt;dbl&gt;) and integers (&lt;int&gt;). Integers keep track of whole numbers, while doubles keep track of decimals (but R often stores whole numbers as doubles).\nCharacter: Text, such as letters, words, and phrases (&lt;chr&gt;, e.g., \"pink\" or \"Clarkia xantiana\").\n\nLogical: Boolean values—TRUE or FALSE (&lt;logi&gt;), often used for comparisons and conditional statements.\n\nFactors: Categorical variables that store predefined levels, often used in statistical modeling. While they resemble character data, they behave differently in analyses. We will ignore them in this chapter but revisit them later.\n\nWhen you load data into R, you should always check to ensure that the data are in the expected format. Here we are surprised to see that growth_rate is a character, because it should be a number. A close inspection shows that in row three someone accidentally entered the letter O instead of the number zero (0) in what should be 1.80.\n\n\n\n# A tibble: 4 × 2\n  ril   growth_rate\n  &lt;chr&gt; &lt;chr&gt;      \n1 A1    1.272      \n2 A100  1.448      \n3 A102  1.8O       \n4 A104  0.816      \n\n\nAsking logical questions We often generate logical variables by asking logical questions of the data. Here is how you do that in R.\n\n\n\nQuestion\nR Syntax\n\n\n\n\nDoes a equal b?\na == b\n\n\nDoes a not equal b?\na != b\n\n\nIs a greater than b?\na &gt; b\n\n\nIs a less than b?\na &lt; b\n\n\nIs a greater than or equal to b?\na &gt;= b\n\n\nIs a less than or equal to b?\na &lt;= b",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Data types in R"
    ]
  },
  {
    "objectID": "book_sections/getting_started/rstudio_orientation.html",
    "href": "book_sections/getting_started/rstudio_orientation.html",
    "title": "• 1. Orientation to RStudio",
    "section": "",
    "text": "Motivating scenario: You have just downloaded R and RStudio, and want to understand all the stuff that you see when you open RStudio.\nLearning goals: By the end of this sub-chapter you should be able to\n\nIdentify the source pane and what to do there.\n\nIdentify the terminal pane and what to see and do there.\n\nIdentify the environment / history pane, what to see and do there, and how to navigate tabs in this pane.\n\nIdentify the file / plot / help / viewer pane, what to see and do there, and how to navigate tabs in this pane.\n\n\n\n\n\n\nAbove, you ran R in this web browser, but more often you will work with R in RStudio. When you open RStudio for the first time, you will see three primary panes. The one on the left works identically to the basic R console. Navigating to ‘File &gt; New File &gt; R Script’ opens a new script and reveals a fourth pane.\n\n\nR Scripts are ways to keep a record of your code so that you can pick up where you left off, build on previous work, and share your efforts. We will introduce R Scripts more formally soon!\n\n\n\nLike the R console above (and all computer languages) RStudio does not “know” what you wrote until you enter it into memory. There are a few ways to do this, but our preferred way is to highlight the code you intend to run, and then click the Run button in the top right portion of the R script pane. Alternatively, press Ctrl+Return for Windows/Linux or ⌘+Return on OS X.\n\n\n\n\n\n\n\n\nFigure 1: More panes = less pain. A brief tour of RStudio’s panes.\n\n\n\n\n\nFigure 1 shows what your RStudio session might look like after doing just a little bit of work:\n\nThe source pane Pane 1 is used for writing and editing scripts, R Markdown files etc. This is where you write reproducible code that can be saved and reused.\nThe console pane Pane 2 is basically the R command prompt from vanilla R, it is where you directly interact with R. You can type commands here to execute them immediately. It will display output, messages, and error logs.\nThe environment / history pane Pane 3 shows what R has in working memory and what it has done.\n\nThe Environment Tab shows all objects (e.g., data frames, vectors) currently in memory.\n\nThe History Tab shows all the commands you have run in your session. You can even search through your history, which can be easier than scrolling through the console.\n\nThe files / plots / help / viewer pane. Pane 4 is remarkably useful!\n\nThe Plots Tab shows the plots generated during your session. You can delete an individual plot by clicking the red X button, or delete all plots by clicking the broom button.\nThe Help Tab: allows you to access documentation and help files.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Orientation to RStudio"
    ]
  },
  {
    "objectID": "book_sections/getting_started/getting_started_summary.html",
    "href": "book_sections/getting_started/getting_started_summary.html",
    "title": "• 1. Getting started summary",
    "section": "",
    "text": "Figure 1: Some pretty R from Allison Horst.\n\n\n\n\nLinks to Summary. Chatbot tutor. Questions. Glossary. R functions. R packages. Additional resources.\n\nChapter summary\nR is (much more than just) a simple calculator – it can keep track of variables, and has functions to make plots, summarize data, and build statistical models. R also has many packages that can extend its capabilities. Now that we are familiar with R, RStudio, vectors, functions, data types and packages, we are ready to build our R skills even further to work with data!\n\n\nChatbot tutor\nPlease interact with this custom chatbot (link here) I have made to help you with this chapter. I suggest interacting with at least ten back-and-forths to ramp up and then stopping when you feel like you got what you needed from it.\n\n\nPractice Questions\n\n\n\n\n\n\n\n\n\nFigure 2: Some encouragement from Allison Horst.\n\n\n\n\nThe interactive R environment below allows you to work without switching tabs.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nQ1) Entering \"p\"^2 into R produces which error?\n\n What error? It works great? Error: object p not found Error: object of type closure is not subsettable Error in “p”^2 : non-numeric argument to binary operator\n\nQ2) Which logical question provides an unexpected answer?\n\n (2.0 + 1.0) == 3.0 (0.2 + 0.1) == 0.3 2^2 &gt; 8 (1/0) == (10 * 1/0)\n\n\n\nClick here for an explanation\n\nThis is a floating-point precision issue. In R (and most programming languages), some decimal values cannot be represented exactly in the binary code that they use under the hood. To see this, try (0.2 + 0.1) - 0.3:\n\n(0.2 + 0.1) - 0.3\n\n[1] 5.551115e-17\n\n\nIf you are worried about floating point errors, use the all.equal() function instead of ==, or round to 10 decimal places before asking logical questions.\n\nQ3) R has a built-in dataset called iris. You can look at it or give it to functions by typing iris. Which variable type is the Species in the iris dataset?\n\n numeric logical character factor\n\nFor the following questions consider the diabetes dataset available at: https://rb.gy/fan785\nQ4) Which variable in the diabetes dataset is a character but should be a number?:\n\n ratio location age frame none\n\nQ5) True OR False: The numeric variable, bp.1d, is a double, but could be changed to an integer without changing any of our analyses: TRUEFALSE\nQ6) Which categorical variable in the dataset is ordinal?\n\n id location gender frame\n\nQ7) You collected five leaves of the wild grape (Vitis riparia) and measured their length and width. You have a table of lengths and widths of each leaf and a formula for grape leaf area (below).\nThe area of a grape leaf is: \\[\\text{leaf area } = 0.851 \\times \\text{ leaf length } \\times \\text{ leaf width}\\] The data are here, each column is a leaf:\n\n\n\n\n\nlength\n5.0\n6.1\n5.8\n4.9\n6.0\n\n\nwidth\n3.2\n3.0\n4.1\n2.9\n4.5\n\n\n\n\n\nThe mean leaf area is \n\n\nClick here for a hint\n\n\nFirst make vectors for length and width\n\nlength = c(5, 6.1, 5.8, 4.9, 6)\nwidth = c(3.2, 3, 4.1, 2.9, 4.5)\nThen multiply these vectors by each other and 0.851.\nFinally find the mean\n\n\n\n\nClick here for the solution\n\n\n# Create length and width vectors\nlength &lt;- c(5, 6.1, 5.8, 4.9, 6)\nwidth &lt;- c(3.2, 3, 4.1, 2.9, 4.5)\n\n\nleaf_areas &lt;- 0.851 * length * width # find area\nmean(leaf_areas)                     # find mean\n\n[1] 16.89916\n\n# or in one step:\n(0.851 * length * width) |&gt;\n  mean()\n\n[1] 16.89916\n\n\n\n\n\n\n\nGlossary of Terms\n\n\nR: A programming language designed for statistical computing and data analysis.\nRStudio: An Integrated Development Environment (IDE) that makes using R more user-friendly.\nVector: An ordered sequence of values of the same data type in R.\nAssignment Operator (&lt;-): Used to store a value in a variable.\nLogical Operator: A symbol used to compare values and return TRUE or FALSE (e.g., ==, !=, &gt;, &lt;).\nNumeric Variable: A variable that represents numbers, either as whole numbers (integers) or decimals (doubles).\nCharacter Variable: A variable that stores text (e.g., \"Clarkia xantiana\").\nPackage: A collection of R functions and data sets that extend R’s capabilities.\n\n\n\n\n\nNew R functions\n\n\nc(): Combines values into a vector.\ninstall.packages(): Installs an R package.\nlibrary(): Loads an installed R package for use.\nlog(): Computes the logarithm of a number, with an optional base.\nmean(): Calculates the average (mean) of a numeric vector.\nread_csv() (readr): Reads a CSV file into R as a data frame.\nround(): Rounds a number to a specified number of decimal places.\nsqrt(): Finds the square root of a number.\nView(): Opens a data frame in a spreadsheet-style viewer.\n\n\n\n\n\nR Packages Introduced\n\n\nbase: The core R package that provides fundamental functions like c(), log(), sqrt(), and round().\nreadr: A tidyverse package for reading rectangular data files (e.g., read_csv()).\ndplyr: A tidyverse package for data manipulation, including mutate(), glimpse(), and across().\nconflicted: Helps resolve function name conflicts when multiple packages have functions with the same name.\n\n\n\n\nAdditional resources\nThese optional resources reinforce or go beyond what we have learned.\n\nR Recipes:\n\nDoing math in R.\n\nUsing R functions.\n\nImporting data from a .csv.\n\nVideos:\n\nCoding your Data Analysis for Success (From Stat454).\n\nWhy use R? (Yaniv Talking).\n\nAccessing R and RStudio (Yaniv Talking).\n\nRStudio orientation (Yaniv Talking).\n\nR functions (Yaniv Talking).\n\nR packages (Yaniv Talking).\n\nLoading data into R (Yaniv Talking).\n\nData types (Yaniv Talking). Uses compression data as an example.",
    "crumbs": [
      "1. Getting started with R",
      "• 1. Getting started summary"
    ]
  },
  {
    "objectID": "toc.html",
    "href": "toc.html",
    "title": "# Rest of Book",
    "section": "",
    "text": "Preliminary material\nPreface: Clarkia and its data // Types of variables",
    "crumbs": [
      "Rest of Book"
    ]
  },
  {
    "objectID": "toc.html#section-i-introduction-to-r",
    "href": "toc.html#section-i-introduction-to-r",
    "title": "# Rest of Book",
    "section": "Section I: Introduction to R",
    "text": "Section I: Introduction to R\n1. Getting Started with R: Functions and vectors // Loading packages and data // Data types // RStudio orientation // Summary of Chapter 1.\n\n2. Working with data in R: Adding variables // Selecting variables // Summarizing variables // Choosing rows // Summary of Working with Data in R.\n\n3. Intro to ggplot: One continuous variable // Saving ggplots // Continuous and categorical // Two categorical variables // Two continuous variables // Many explanatory variables // Summary of Intro to ggplot.\n\n4. Reproducible science: Collecting data // Reproducible analyses // Summary of Reproducible Science.",
    "crumbs": [
      "Rest of Book"
    ]
  },
  {
    "objectID": "toc.html#second-section-summarizing-data",
    "href": "toc.html#second-section-summarizing-data",
    "title": "# Rest of Book",
    "section": "Second Section: Summarizing Data",
    "text": "Second Section: Summarizing Data\n5. Univariate Summaries: Summarizing shape // Changing shape // Summarizing center // Summarizing variability // Summary of Summaries.\n6. Associations: Categorical vs. continuous // Two categorical variables // Two continuous variables // Summary of Associations.\n7. Linear Models: Mean as a model // Categorical predictors // Regression // Two predictors // Summary of Desciptive Linear Modelling.",
    "crumbs": [
      "Rest of Book"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Behrouzi, P., & Wit, E. (2017). Detecting epistatic selection with\npartially observed genotype data using copula graphical models.\nJournal of the Royal Statistical Society: Series C (Applied\nStatistics), 68. https://doi.org/10.1111/rssc.12287\n\n\nBergstrom, C. T., & West, J. D. (2020). Calling bullshit: The\nart of skepticism in a data-driven world. Random House.\n\n\nBryan, J. J. (2020). STAT 545: Data wrangling, exploration, and\nanalysis with r. Bookdown. https://stat545.com\n\n\nGrolemund, G. (2014). Hands-on programming with r: Write your own\nfunctions and simulations. \" O’Reilly Media, Inc.\".\n\n\nGrolemund, G., & Wickham, H. (2018). R for data science.\n\n\nHiggins, P. D. R. (2024). Reproducible medical research with r.\nBookdown. https://bookdown.org/pdr_higgins/rmrwr/\n\n\nIsmay, C., & Kim, A. Y. (2019). Statistical inference via data\nscience: A ModernDive into r and the tidyverse. CRC Press.\n\n\nSianta, S. A., Moeller, D. A., & Brandvain, Y. (2024). The extent of\nintrogression between incipient &lt;i&gt;clarkia&lt;/i&gt; species is\ndetermined by temporal environmental variation and mating system.\nProceedings of the National Academy of Sciences,\n121(12), e2316008121. https://doi.org/10.1073/pnas.2316008121\n\n\nWhitlock, M. C., & Schluter, D. (2020). The analysis of\nbiological data (Third). Macmillan.\n\n\nWilke, C. O. (2019). Fundamentals of data visualization: A primer on\nmaking informative and compelling figures. O’Reilly Media.",
    "crumbs": [
      "References"
    ]
  }
]