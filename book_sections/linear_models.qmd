# 7. Linear Models {#linear_models}



```{r}
#| echo: false
#| message: false
#| warning: false
library(tweetrmd)
library(knitr)
library(dplyr)
library(readr)
library(stringr)
library(DT)
library(webexercises)
library(ggplot2)
library(tidyr)
source("../_common.R") 

ril_link <- "https://raw.githubusercontent.com/ybrandvain/datasets/refs/heads/master/clarkia_rils.csv"
ril_data <- readr::read_csv(ril_link) |>
  dplyr::mutate(growth_rate = case_when(growth_rate =="1.8O" ~ "1.80",
                                          .default = growth_rate),  
                growth_rate = as.numeric(growth_rate),
                visited = mean_visits > 0)
gc_rils <- ril_data |>
  filter(location == "GC", !is.na(prop_hybrid), ! is.na(mean_visits))|>
  select(petal_color, petal_area_mm, num_hybrid, offspring_genotyped, prop_hybrid, mean_visits , asd_mm )
```



::: {.motivation style="background-color: #ffe6f7; padding: 10px; border: 1px solid #ddd; border-radius: 5px;"}

**Motivating Scenario:** 
You want to move beyond simply plotting and summarizing associations and start modeling relationships between variables.  

**Learning Goals: By the end of this chapter, you should be able to:**

1. **Explain what a linear model is and what it does**.   
   - Understand a linear model as a way of estimating the conditional mean of a response variable. 

2. **Interpret the components of a linear model**   

   - Explain the meaning of intercepts, slopes (effect sizes), and predicted values.

   - Define and interpret residuals and the residual standard deviation.   

3. **Estimate a slope from a dataset**  with math and with R.    

4. **Estimate a conditional mean from a linear model with multiple explanatory variables.**    

:::     

---



<article class="drop-cap">Reality is messy. There's too much going on to notice everything at once. That's why we make models — simplified, abstract descriptions of the world — that help us focus on patterns we care about. Models aren't perfect copies of reality — they leave things out — and that's the point. A good model keeps what's important and ignores the rest. In statistics, models help us summarize what we observe, understand relationships,  make predictions, and even allow us to test hypotheses.</article>


In this section, we'll introduce statistical models as simplified descriptions of the world. You'll notice that you're already familiar with some simple models. For example, the mean and variance provide a basic model for a single numeric variable, while a conditional mean and pooled variance describe a numeric response variable with a categorical explanatory variable. 

```{r}
#| echo: false
#| column: margin
#| label: fig-holiday
#| fig-cap: "The Holiday Junction -- one of my favorite scientific models, and an associated  statistical model.  (A) A scientific model of the idealized process of double-strand break repair (DSBR) and synthesis-dependent strand annealing (SDSA) pathways, leading to crossover or non-crossover products. From [wikipedia](https://en.wikipedia.org/wiki/Holliday_junction). (B) A statistical model of the observed frequencies of different DNA joint molecule types (X-shape, Type I, Type II, Complex) under different biochemical conditions (with or without RecU protein, and varying magnesium concentrations). From @suzuki2014"
#| fig-alt: "A two-panel figure. Panel A shows a diagram of double-strand break repair: broken DNA strands undergo resection, strand invasion, and DNA synthesis, leading to either double-strand break repair (DSBR) or synthesis-dependent strand annealing (SDSA) pathways, resulting in crossover or non-crossover products. Panel B is a bar graph showing frequencies of different DNA joint molecule types (X-shape, Type I, Type II, Complex) across three conditions (without RecU, RecU with low magnesium, and RecU with high magnesium). The X-shape structure is most common, with lower frequencies of other types."
include_graphics("../figs/summarizing_data/linear_models/holiday_junction_b.png")
```

## Statistical models are not scientific models 

This is a **BIO**statistics book. It is written by and for biologists interested in biological ideas. We are inspired by biological questions generated by scientific understanding and scientific models of the world. However, a major way in which we evaluate such scientific models is via statistical models and hypotheses. Confusing a statistical model for a scientific model is a common and understandable mistake  that we should avoid. Scientific models and statistical models are different: 

- **Scientific models** are based on our understanding of the science -- in this case biology. Biological models come from us making simplified  abstractions of complex systems (like considering predator-prey interactions, plant pollination, cancer progression, or meiosis (@fig-holiday A)). Great scientific models explain what we see, make interesting predictions, and  are consistent with our broader scientific understanding.    


- **Statistical models** on the other hand, are mathematical ways to describe patterns in data (e.g. @fig-holiday B). Statistical models know nothing about Lotka-Voltera, pollination or human physiology. 

Because statistical models know nothing about science it is our job to build scientific studies  best suited for clean statistical interpretation, build statistical models that best represent our biological questions, and interpret statistical results as statistical. We must always recenter biology in interpreting any statistical outcome. 



### Scientific & statistical models: The *Clarkia* case study

In our *Clarkia* example, the big-picture scientific model is that when *parviflora* came back into contact with its close relative, *xantiana*, it evolved traits — such as smaller petals — to avoid producing hybrids.  No single statistical model or study fully captures this scientific model. Instead, we design experiments to evaluate pieces of the model. For example, we:

1. **Compare petal area** between *parviflora* plants from populations that occur with *xantiana* (sympatric populations) and those from populations far away from *xantiana* (allopatric populations).

2. **Conduct an experiment** by planting individuals from sympatric and allopatric *parviflora* populations in the same environment as *xantiana*, and comparing the amount of hybrid seed set by plants from each origin.

3. **Generate Recombinant Inbred Lines (RILs)** between sympatric and allopatric *parviflora* populations, and examine whether petal area is associated with the proportion of hybrid seeds produced.

As you can see, statistical models don’t "know" anything about biology — they simply describe patterns in data.   It’s up to us, as biologists, to design experiments carefully, choose the right statistical models, and interpret results in light of our biological hypotheses.



## Linear models 

Linear models are among the most common types of statistical model. Linear models estimate the conditional mean of the $i^{th}$ observation of a uous response variable, $\hat{Y}_i$ for a (combination) of value(s) of the explanatory variables ($\text{explanatory variables}_i$): 



\begin{equation} 
\hat{Y}_i = f(\text{explanatory variables}_i)
\end{equation} 


:::aside
**Conditional mean:** The expected value of a response variable given specific values of the explanatory variables (i.e., the model’s best guess for the response based on the explanatory variables).  
:::



These models are "linear" because we get this estimate of the conditional mean, $\hat{Y}_i$, by adding up all components of the model. That is, each explanatory variable $y_{j,i}$ is multiplied by its effect size $b_j$.  So, for example, $\hat{Y}_i$ equals the parameter estimate for the "intercept", $a$ plus its value for the first explanatory variable, $y_{1,i}$, times the effect of this variable, $b_1$, plus its value for the second explanatory variable, $y_{2,i}$ times the effect of this variable, $b_2$, and so on for all included predictors.

\begin{equation} 
\hat{Y}_i = a + b_1  y_{1,i} + b_2 y_{2,i} + \dots{}
\end{equation}


:::learnmore
**OPTIONAL / ADVANCED, FOR MATH NERDS:**.  If you have a background in linear algebra, it might help to see a linear model in matrix notation. 

The first matrix below is known as the  *design matrix*. Each row corresponds to an individual, and each entry in the $i$th row corresponds to that individual's value for a given explanatory variable. We take the dot product of this matrix and our estimated parameters to get the predictions for each individual. The equation below has $n$ individuals and $k$ explanatory variables. Note that every individual has a value of 1 for the intercept.


\begin{equation} 
\begin{pmatrix}
    1 & y_{1,1} & y_{2,1} & \dots  & y_{k,1} \\
    1 & y_{1,2} & y_{2,2} & \dots  & y_{k,2} \\
    \vdots & \vdots & \vdots & \ddots & \vdots \\
    1 & y_{1,n} & y_{2,n} & \dots  & y_{k,n}
\end{pmatrix}
\cdot 
\begin{pmatrix}
    a \\
    b_{1}\\
    b_{2}\\
    \vdots  \\
     b_{k}
\end{pmatrix}
=
\begin{pmatrix}
    \hat{Y}_1 \\
    \hat{Y}_2\\
    \vdots  \\
    \hat{Y}_n
\end{pmatrix}
\end{equation}
:::
 
 

## Residuals and Variance in Linear Models

As with a simple mean, actual observations usually differ from their predicted (conditional mean) values.  
The difference between an observed value for an individual ($Y_i$) and the predicted value from the linear model ($\hat{Y}_i$) is called the residual, $e_i$:

:::aside
**Residual:** The difference between an observed value and its predicted value from a linear model  (i.e., the conditional mean given that observation’s values for the explanatory variables).
::: 

$$e_i = Y_i - \hat{Y}_i$$

You can also rearrange this to think about it the other way around:

$$Y_i = \hat{Y}_i + e_i$$


Just like when we summarized variability around a simple mean, we can summarize variability around a model's predictions by looking at the spread of the residuals. That is, linear models don’t just give us a conditional mean — they also give us a way to estimate how far observations tend to vary around that mean.

We calculate the residual variance (and residual standard deviation) of the residuals like this:




$$\text{Residual variance} = \frac{ \sum e_i^2}{n-1}$$

:::aside
**A small caveat:** The equation for the residual variance is  a bit off — the denominator should actually be $n - p$, where $p$ is the number of parameters estimated in our model (including the intercept). But it's close enough for now. We can worry about being precise later — in much of statistics, being approximately right is good enough.  <br><br> <br>
:::

We can use the residual variance to find the residual standard deviation: $\text{Residual standard deviation} = \sqrt{\frac{\sum e_i^2}{n-1}}$.  


We can think of the residual standard deviation  as telling us, on average, how far away from their predicted value individuals are expected to be. In fact, when we calculated the pooled standard deviation earlier, we were already doing a special case of what we now call the residual standard deviation — just in the simple situation of two groups.

## Assumptions, Caveats and our limited ambitions 

In this section, we focus on building and interpreting linear models as descriptions of data. We will put off a formal discussion of what makes a linear model reasonable — and how to diagnose whether a model fits its assumptions — until later.  In the meantime, as we build and interpret models, we'll keep an informal eye out for clues that something might be wrong — but we'll learn formal tools to evaluate if a specific model meets assumptions of a linear model later.

This doesn’t mean that interpreting linear models is more important than evaluating whether they are any good (in fact, in real research, interpreting and evaluating models are inseparable). It just means it’s hard to teach a bunch of interconnected ideas and approaches all at once — and after years of experimentation, I’ve found this approach to be the most successful. That said, before you conduct any serious linear modeling work, you should definitely jump ahead and read **PART 3** of this book, where we discuss model assumptions and how to check them carefully.  


## Let's get started introducing linear models as summaries!    

Throughout this chapter we will model a single response variable -- the proportion of hybrids that a mom produced. As you see below, much of this chapter recasts concepts you have already learned in the framework of a linear model. 

- We will start with the [simplest linear model -- the mean](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/mean.html). While we have already introduced the mean, introducing it in the context of a linear model helps us prepare for our next steps!   

- We will then introduce [linear models with an explanatory categorical predictor](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_cat_pred.html). Starting with a binary predictor (petal color), we will recast our understanding of a conditional mean in the context of a linear model. We will then expand to a categorical explanatory variable with multiple levels (location). 


- Next we show how [linear models can predict one numeric variable from another](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/regression.html) -- in this case we predict proportion hybrid seed from petal area. Building on our understanding of covariance and correlation, we introduce the slope and intercept.  

- Finally we introduce [linear models with two predictors](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/two_predictors.html). Specifically, we extend beyond what we have learned so far - we build a linear model to predict a numeric response (proportion of hybrid seeds) from a categorical (petal color) and numeric (petal area) predictor. 


We conclude (as usual) with a [ chapter summary](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html), [practice questions](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html#practice-questions), a [glossary](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html#glossary-of-terms), a review of [R functions](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html#key-r-functions) and [R packages](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html#r-packages-introduced) introduced, and [present additional resources](https://ybrandvain.quarto.pub/applied-biostatistics-summarizingdata/book_sections/linear_models/lm_summary.html#additional-resources).  On the whole, this chapter extends our ability to summarize data while preparing us for the more sophisticated linear modeling and hypothesis testing we will pursue later in the book. 

